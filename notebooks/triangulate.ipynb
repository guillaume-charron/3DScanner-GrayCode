{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "from open3d import core as o3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load calib results\n",
    "proj_mtx =  np.load('../data/calib_results/bouda/proj_mtx.npy', )\n",
    "proj_dist = np.load('../data/calib_results/bouda/proj_dist.npy', )\n",
    "cam_mtx =   np.load('../data/calib_results/cam_1440/cam_mtx.npy', )\n",
    "cam_dist =  np.load('../data/calib_results/cam_1440/cam_dist.npy')\n",
    "proj_R =    np.load('../data/R.npy')\n",
    "proj_T =    np.load('../data/T.npy')\n",
    "R1 =        np.load('../data/R1.npy')\n",
    "R2 =        np.load('../data/R2.npy')\n",
    "P1 =        np.load('../data/P1.npy')\n",
    "P2 =        np.load('../data/P2.npy')\n",
    "\n",
    "proj_w, proj_h = (1280, 720)\n",
    "calib_proj_w, calib_proj_h = (1920, 1080)\n",
    "\n",
    "cam_w, cam_h = (2560, 1440)\n",
    "scale_x = proj_w / calib_proj_w\n",
    "scale_y = proj_h / calib_proj_h\n",
    "proj_mtx[0, :] = proj_mtx[0, :] * scale_x\n",
    "proj_mtx[1, :] = proj_mtx[1, :] * scale_y\n",
    "\n",
    "base_path = '../data/recordings/elephant_800/'\n",
    "h_pixels = np.load(base_path+'h_pixels.npy')\n",
    "v_pixels = np.load(base_path+'v_pixels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pts = []\n",
    "proj_pts = []\n",
    "colors = []\n",
    "\n",
    "# Get white image to extract colors\n",
    "img_white = cv2.imread(base_path + '/frame_1.jpg', cv2.IMREAD_COLOR)\n",
    "img_white = cv2.cvtColor(img_white, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "for i in range(1000, 1700):\n",
    "    for j in range(400, 1000):\n",
    "# for i in range(cam_w):\n",
    "#     for j in range(cam_h):\n",
    "        h_value = h_pixels[j, i]\n",
    "        v_value = v_pixels[j, i]\n",
    "        if h_value == -1 or v_value == -1:\n",
    "            pass\n",
    "        else:\n",
    "            cam_pts.append([i,j])\n",
    "            h_value = min(proj_w-1, h_value)\n",
    "            v_value = min(proj_h-1, v_value)\n",
    "            proj_pts.append([ h_value, v_value])\n",
    "            colors.append(img_white[j, i, :])\n",
    "\n",
    "cam_pts = np.array(cam_pts, dtype=np.float32)\n",
    "proj_pts = np.array(proj_pts, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newcameramtx, roi = cv2.getOptimalNewCameraMatrix(cam_mtx, cam_dist, (1920,1080), 1, (1920,1080))\n",
    "# newprojmtx, roi = cv2.getOptimalNewCameraMatrix(proj_mtx, proj_dist, (1920,1080), 1, (1280,720))\n",
    "# cam_pts_homo = cv2.undistortPoints(np.expand_dims(cam_pts, axis=1), cam_mtx, cam_dist, None, newcameramtx)\n",
    "# proj_pts_homo = cv2.undistortPoints(np.expand_dims(proj_pts, axis=1), proj_mtx, proj_dist, None, newprojmtx)\n",
    "\n",
    "cam_pts_homo = cv2.convertPointsToHomogeneous(cv2.undistortPoints(np.expand_dims(cam_pts, axis=1), cam_mtx, cam_dist, R=proj_R))[:,0].T\n",
    "proj_pts_homo = cv2.convertPointsToHomogeneous(cv2.undistortPoints(np.expand_dims(proj_pts, axis=1), proj_mtx, proj_dist))[:,0].T\n",
    "T = proj_T[:,0]\n",
    "\n",
    "# Took from https://github.com/caoandong/Projector_Calibration/blob/master/visual_calib.py\n",
    "TLen = np.linalg.norm(T)\n",
    "NormedL = cam_pts_homo/np.linalg.norm(cam_pts_homo, axis=0)\n",
    "alpha = np.arccos(np.dot(-T, NormedL)/TLen)\n",
    "degalpha = alpha*180/np.pi\n",
    "beta = np.arccos(np.dot(T, proj_pts_homo)/(TLen*np.linalg.norm(proj_pts_homo, axis=0)))\n",
    "degbeta = beta*180/np.pi\n",
    "gamma = np.pi - alpha - beta\n",
    "P_len = TLen*np.sin(beta)/np.sin(gamma)\n",
    "Pts = NormedL*P_len\n",
    "\n",
    "colors_array = np.array(colors).astype(np.float64)/255.0\n",
    "\n",
    "filter = (Pts[2] < 1.5) & (Pts[2] > -0.5)\n",
    "Pts_filtered = Pts[:, filter]\n",
    "\n",
    "pcd = o3d.t.geometry.PointCloud(o3c.Tensor(Pts[:, filter].T, o3c.float32))\n",
    "pcd = pcd.to_legacy()\n",
    "pcd.colors = o3d.cpu.pybind.utility.Vector3dVector(colors_array[filter])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "# For bouda\n",
    "# o3d.visualization.draw_geometries([pcd], zoom=0.45999999999999974,\n",
    "#                                   front=[ -0.54775242945121028, -0.15624350092055739, -0.82192167780779746 ],\n",
    "#                                   lookat=[ 0.30860175937414169, 0.14094289019703865, 0.47711528837680817 ],\n",
    "#                                   up=[ 0.0089500924594270986, -0.9834453515238939, 0.18098380151552931 ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift6145-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
